{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1137809e-2f37-4063-a9aa-5336181d1ed0",
   "metadata": {},
   "source": [
    "# SPARK101 EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa25dcb-e5a1-49a0-9227-ebce2ea96717",
   "metadata": {},
   "source": [
    "## 1. **Create a spark data frame that contains your favorite programming languages.**\n",
    "\n",
    "* The name of the column should be language  \n",
    "* View the schema of the dataframe  \n",
    "* Output the shape of the dataframe  \n",
    "* Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c28e45-82ec-47e0-ab95-c596f81687a2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab7bbbb-92d2-46e4-bf1a-5814125511d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pydataset import data\n",
    "# from vega_datasets import data\n",
    "\n",
    "# Note: The pyspark avg and mean functions are aliases of eachother\n",
    "from pyspark.sql.functions import col, expr, concat, sum, avg, min, max, count, mean, lit, regexp_extract, regexp_replace, when, asc, desc, month, year, quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aafb40-a2a2-43b9-a787-a9e3418aef63",
   "metadata": {},
   "source": [
    "### Visualization (or Lack Therof)\n",
    "\n",
    "Spark does not provide a way to do visualization with their dataframes. To\n",
    "visualize data from spark, you should use the `.toPandas` method on a spark\n",
    "dataframe to convert it to a pandas dataframe, then visualize as you normally\n",
    "would.\n",
    "\n",
    "!!!warning \"Converting to A Pandas Dataframe\"\n",
    "    Converting a spark dataframe to a pandas dataframe will pull all the data into memory, so make sure you have enough available memory to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd804dbf-9986-46cd-b944-13f4588b9b7b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [PySpark API Docs](https://spark.apache.org/docs/latest/api/python/index.html)\n",
    "- [Spark SQL Programming Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html) -- Note that the docs here show examples in many different programming languages, make sure you choose Python.\n",
    "- [DataFrame class](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame)\n",
    "- [Column class](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column)\n",
    "- [pyspark.sql.functions module](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions)\n",
    "- `df.na`: [DataFrameNaFunctions class](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameNaFunctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b5452c-d9ff-483f-9b3e-aa6b42578d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import host, username, password\n",
    "\n",
    "def get_connection(database, host=host, user=username, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4637d9-4b28-445b-8898-3d2b2f854b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"SELECT * FROM source\"\"\"\n",
    "# url = get_connection(\"311_data\")\n",
    "# source_df = pd.read_sql(query, url)\n",
    "# source_df = spark.createDataFrame(source_df)\n",
    "# source_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abb006a-9492-4503-9476-509cdfa1496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/17 12:58:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/17 12:58:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d5a330-ef4e-46a6-99f3-066fcedce5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# utilized demo code to populate mpg\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "\n",
    "mpg.write.json(\"data/mpg_json\", mode=\"overwrite\")\n",
    "\n",
    "# like much else in spark, there's multiple ways we could do this:\n",
    "(\n",
    "    mpg.write.format(\"csv\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(\"data/mpg_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786856c-fb62-45c2-bd57-a398b8c65af9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fada1-a37c-48c1-8686-1a517ae3c5e9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f64ec-4e16-4b7c-a9c4-787303288391",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399c8d2-c82d-4cab-9941-c8131d1a17c1",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d72f0-bc77-4802-a1fd-968876e8646d",
   "metadata": {},
   "source": [
    "## 2. **Load the mpg dataset as a spark dataframe.**\n",
    "\n",
    "$a.$ Create 1 column of output that contains a message like the one below:\n",
    "\n",
    " `The 1999 audi a4 has a 4 cylinder engine.`\n",
    " \n",
    "For each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0792b6-0039-4113-8176-f11fba209240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|             model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|                a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|                a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|                a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|  auto(s6)|  4| 19| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|manual(m5)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|manual(m6)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a6 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 24|  p|midsize|\n",
      "|        audi|        a6 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|midsize|\n",
      "|        audi|        a6 quattro|  4.2|2008|  8|  auto(s6)|  4| 16| 23|  p|midsize|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 14| 20|  r|    suv|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 11| 15|  e|    suv|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# displaying top 20 of the vehicles\n",
    "# concat can be used to create a message like inthe example.\n",
    "mpg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770456ab-4f66-4279-95c3-a08ad8edc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.select(\n",
    "    co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c6beb-04a2-4c21-907d-ca10f357025c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814bca7-d747-4ee7-a5a0-cc3bd2018c68",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e80e3-ea4c-427b-8ef3-d6d81496af0e",
   "metadata": {},
   "source": [
    "$b.$ Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006e03a-dba4-47b7-b384-43b1ba5cc258",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d79b8-5bd1-4f93-85b5-db7967a7b7e0",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87dc02-07c6-4939-b842-8da33d572148",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2419ec6-2976-465b-bb00-e075a85bde42",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f2c2b-181a-4349-9dbd-9f90af98389c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04ff90-f24c-4da7-b9a8-1b2c307a0b63",
   "metadata": {},
   "source": [
    "## 3. **Load the tips dataset as a spark dataframe.**\n",
    "\n",
    "$a.$ What percentage of observations are smokers?  \n",
    "\n",
    "$b.$ Create a column that contains the tip percentage  \n",
    "\n",
    "$c.$ Calculate the average tip percentage for each combination of sex and smoker.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf49dc2-a043-4aae-994a-75720db749c9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b17618-5aab-49ce-9b28-b190fb175b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8340c95-4112-416c-b29e-5f90c6fd7004",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01419049-4fc4-4f77-9308-4e6b639c5db2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6c615-610e-48a3-891a-f4d5d867a338",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a847fe1-0903-42c5-9ecf-efe8bc592610",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc396a-0fcc-45b5-8997-0e58c9528753",
   "metadata": {},
   "source": [
    "## 4. **Use the seattle weather dataset referenced in the lesson to answer the questions below.**\n",
    "\n",
    "* Convert the temperatures to fahrenheit.\n",
    "\n",
    "* Which month has the most rain, on average?\n",
    "   \n",
    "* Which year was the windiest?\n",
    "\n",
    "* What is the most frequent type of weather in January?\n",
    "  \n",
    "* What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "  \n",
    "* What percentage of days were rainy in q3 of 2015?\n",
    "  \n",
    "* For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c75d0e-6b65-4b9c-8ce1-0a1ef032a775",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e0372-b409-43d5-b7e4-be6bb3a4b756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41dfe4ee-622b-4fa4-b936-fe6743bdd113",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
